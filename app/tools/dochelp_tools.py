from __future__ import annotations

from langchain_core.tools import tool
from typing import List, Dict, Any
from pathlib import Path

from app.services import profile_text
from app.services import insight_services
from app.services import ingestion_db
from .generic_tools import _extract_keywords as compute_keywords

@tool("chat_over_file")
def chat_over_file(file: str, query: str) -> str:
    """
    Answer a natural language question grounded in the given uploaded file.

    Args:
        file: The filename under the uploads directory that has been ingested.
        query: The user's question to answer using the file's content.

    Returns:
        A string answer generated by the model and retrieval pipeline.
    """
    result = chat_service.answer(
        file,
        query,
        k=12,
        score_threshold=0.45,
        strict=True,
    )
    # chat_service.answer returns a dict with key "response"
    if isinstance(result, dict) and "response" in result:
        return str(result["response"])  # type: ignore[index]
    return str(result)

@tool("ingest_document")
def ingest_document(file: str, agent: str = "DocHelp") -> str:
    """
    DocHelp: index a document and persist a generic record with keywords and collection info.
    """
    try:
        text, loader = profile_text.load_text(file)
        keywords = compute_keywords(text)
        insight_services.create_vector_store(file, force=False)
        status = insight_services.check_vector_ready(file)
        collection = status.get("collection") if isinstance(status, dict) else None
        stem = Path(file).stem

        ingestion_db.upsert_document(
            agent=agent,
            file=file,
            doc_type="document",
            title=stem,
            tags=[],
            keywords=keywords,
            vector_collection=str(collection or ""),
            metadata={"loader": loader},
        )
        return f"Ingested document '{file}' via {loader}; collection={collection}; keywords={len(keywords)}"
    except Exception as e:
        return f"Failed to ingest document '{file}': {e}"


@tool("list_indexed_docs_db")
def list_indexed_docs_db(agent: str = "DocHelp") -> str:
    """
    List documents persisted for DocHelp from the generic ingestion DB with collection names and keywords count.
    """
    try:
        rows = ingestion_db.list_documents(agent, doc_type="document")
        out: List[Dict[str, Any]] = []
        for r in rows:
            out.append(
                {
                    "file": r.get("file"),
                    "title": r.get("title"),
                    "vector_collection": r.get("vector_collection"),
                    "keywords_count": len(r.get("keywords") or []),
                    "updated_at": r.get("updated_at"),
                }
            )
        return str({"documents": out})
    except Exception as e:
        return str({"documents": [], "error": str(e)})

